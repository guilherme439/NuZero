[optimization]
parallel_testing = True
state_cache = 'per_game'

[actors]
num_actors = 6
chunk_size = 64

[running]
early_fill = 500
num_games_per_batch = 250
num_batches = 50
num_wr_testing_games = 50

test_set = False
num_test_set_games = 0

[frequency]
save_frequency = 1
test_frequency = 1
debug_frequency = 1
storage_frequency = 1
plot_frequency = 1
plot_reset = 100

[recurrent_networks]
num_train_iterations = 2
num_pred_iterations = 2
num_test_iterations = 2

[learning]
shared_storage_size = 4
replay_window_size = 6000
learning_method = 'samples'

[epochs]
batch_size = 32
learning_epochs = 8

[samples]
batch_size = 128
num_samples = 256
late_heavy = True

[optimizer]
optimizer = 'Adam'
learning_rate = 2e-5
scheduler_boundaries = [100e3, 600e3, 1500e3]
scheduler_gamma = 0.1
weight_decay = 1e-05
momentum = 0.9

