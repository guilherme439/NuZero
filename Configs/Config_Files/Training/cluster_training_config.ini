[optimization]
state_cache = 'disabled'

[actors]
num_actors = 15
chunk_size = 300

[running]
early_fill = 1000
num_games_per_batch = 1000
num_batches = 100
testing_mode = 'mcts'
num_wr_testing_games = 100
test_set = False
num_test_set_games = 0

[frequency]
save_frequency = 1
test_frequency = 2
debug_frequency = 1
storage_frequency = 1
plot_frequency = 2
plot_reset = 1000

[recurrent_networks]
num_train_iterations = 3
num_pred_iterations = 3
num_test_iterations = 3

[learning]
shared_storage_size = 3
replay_window_size = 10000
learning_method = 'samples'
normalize_loss = False
batch_extraction = 'local'
skip_target = 'policy'
skip_frequency = 50000

[epochs]
batch_size = 2048
learning_epochs = 1
plot_epoch = False

[samples]
batch_size = 1024
num_samples = 8
late_heavy = True

[optimizer]
optimizer = 'SGD'
learning_rate = 1e-5
scheduler_boundaries = [100e3, 600e3, 1500e3]
scheduler_gamma = 0.1
weight_decay = 1e-08
momentum = 0.9

